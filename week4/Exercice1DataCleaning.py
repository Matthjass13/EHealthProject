import pandas as pd


# ğŸ”¹ 1. Lire le fichier CSV
df = pd.read_csv("iris_to_clean.csv")  



# --------------------------------------------------
# DUPLICATES

# ğŸ”¹ 2. Afficher les 5 premiÃ¨res lignes
#print(df.head())
# ğŸ”¹ 3. VÃ©rifier les infos sur les colonnes
#print(df.info())

# 4 lignes dupliquÃ©es
print(df.duplicated().sum())

# Afficher les lignes dupliquÃ©es
print(df[df.duplicated()])

# Effacer les lignes dupliquÃ©es
df.drop_duplicates(inplace=True)
df.to_csv("iris_to_clean.csv", index=False)





# --------------------------------------------------
# MISSSING VALUES

# 2ï¸âƒ£ VÃ©rifier sâ€™il y a des valeurs manquantes
print("\n--- VÃ©rification des valeurs manquantes ---")
missing_count = df.isnull().sum()
missing_percent = (missing_count / len(df)) * 100

# Combiner compte et pourcentage dans un seul tableau
missing_table = pd.DataFrame({
    'Missing Values': missing_count,
    'Percentage (%)': missing_percent
}).sort_values(by='Missing Values', ascending=False)

print(missing_table)

# Afficher uniquement les lignes contenant des valeurs manquantes
print("\n--- Lignes avec valeurs manquantes ---")
print(df[df.isnull().any(axis=1)])

# ğŸ§¹ Exemple : ici on choisit de remplacer les valeurs manquantes
# par la moyenne pour les colonnes numÃ©riques
df.fillna(df.mean(numeric_only=True), inplace=True)

# VÃ©rifier aprÃ¨s traitement
print("\n--- VÃ©rification aprÃ¨s traitement ---")
print(df.isnull().sum())

# (Optionnel) Sauvegarder le dataset nettoyÃ©
df.to_csv("iris_no_missing_values.csv", index=False)
print("\nâœ… Dataset nettoyÃ© enregistrÃ© sous 'iris_no_missing_values.csv'")




# --------------------------------------------------
# OUTLIERS

print("\n--- VÃ©rification des outliers ---")

# 2ï¸âƒ£ DÃ©tection des outliers avec la mÃ©thode IQR (Interquartile Range)
# Cette mÃ©thode est robuste et trÃ¨s utilisÃ©e pour identifier les valeurs extrÃªmes

def detect_outliers_iqr(data):
    outlier_indices = []
    
    for col in data.select_dtypes(include=['float64', 'int64']).columns:
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # Trouver les indices oÃ¹ la valeur est en dehors des bornes
        outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)].index
        outlier_indices.extend(outliers)
        
        print(f"Colonne '{col}' â†’ bornes [{lower_bound:.2f}, {upper_bound:.2f}], outliers trouvÃ©s : {len(outliers)}")
    
    # Retourner les indices uniques
    return list(set(outlier_indices))

# 3ï¸âƒ£ Identifier les outliers
outliers = detect_outliers_iqr(df)
print(f"\nNombre total de lignes contenant des outliers : {len(outliers)}")

# Afficher les lignes suspectes (si tu veux les examiner avant suppression)
print("\n--- Lignes suspectes ---")
print(df.loc[outliers])

# Supprimer les *non-true* outliers (valeurs aberrantes clairement erronÃ©es)
# Ici on suppose quâ€™on supprime toutes les lignes dÃ©tectÃ©es comme outliers :
df_clean = df.drop(index=outliers)

# VÃ©rifier le rÃ©sultat
print(f"\nâœ… Nombre de lignes avant nettoyage : {len(df)}")
print(f"âœ… Nombre de lignes aprÃ¨s suppression des outliers : {len(df_clean)}")

# (Optionnel) Sauvegarder le dataset propre
df_clean.to_csv("iris_no_outliers.csv", index=False)
print("\nâœ… Dataset nettoyÃ© enregistrÃ© sous 'iris_no_outliers.csv'")
